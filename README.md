## Capstone-UCSD — End-to-End Chatbot Filtration System

This repository delivers a complete pipeline for building, evaluating, and deploying a security-focused chatbot filtration service. It includes data wrangling, model experimentation (traditional ML, deep learning, transformers), a FastAPI policy gateway with configurable thresholds, human-in-the-loop curation, and EDA/cleaning tools.

### Repository Map
- `2-Data_Exploration/` — early exploration scripts and combined dataset artifacts
- `3-Project_Proposal/` — proposal and scope docs
- `4-Survey_Existing_Research/` — literature/code survey and reproductions
- `5-Data_Wrangling/` — dataset assembly, cleaning demos, and scripts
- `7-Experiment_With_Models/` — production-grade ML experiment framework and results
- `9-Deployment_Method_&_Engineering_Plan/` — Step 9 engineering/deployment plan
- `10_11_&_12-Deployment_Architecture/` — Steps 10–12: API, UIs, curation, EDA, Docker
- `dataset_backups/` — dataset snapshots for safety
- `LICENSE` — MIT license

## End-to-End Quickstart
1) Prepare data (optional if using existing datasets)
   - See `5-Data_Wrangling/DEMO_README.md` for a reproducible cleaning demo
   - Outputs structured `combined.json`-style datasets

2) Train and evaluate models
   - cd `Capstone-UCSD/7-Experiment_With_Models`
   - `pip install -r requirements.txt`
   - `python run_pipeline.py` (trains all configured models; writes results and artifacts)
   - Best model and metrics available under `7-Experiment_With_Models/results/`

3) Deploy the filtration service (Steps 10–12)
   - cd `Capstone-UCSD/10_11_&_12-Deployment_Architecture`
   - `python3 -m venv .venv && source .venv/bin/activate`
   - `pip install -r requirements.txt httpx`
   - Optional: `export HF_MODEL_ID=xlm-roberta-base` (stub used if unset)
   - Start API: `./.venv/bin/uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload`

4) Use the UIs and APIs
   - Config + test UI: `http://127.0.0.1:8000/ui`
   - Reviewer UI (table labeling): `http://127.0.0.1:8000/reviewer`
   - Downstream mock (optional): `uvicorn app.downstream_mock:app --host 127.0.0.1 --port 8001`

5) Curation workflow (human-in-the-loop)
   - Enqueue: `curl -s -X POST localhost:8000/ingest -H 'Content-Type: application/json' -d '{"prompt":"example"}'`
   - Review next: `curl -s localhost:8000/review/next`
   - Label: `curl -s -X POST localhost:8000/review/<id> -H 'Content-Type: application/json' -d '{"label":"1"}'`
   - Export replacements: `curl -s localhost:8000/export/replace`

## What the Whole Repo Delivers
- **Data wrangling and quality control**: scripts/notebooks to clean, deduplicate, normalize, and balance datasets, with a demo notebook for reproducibility
- **Model experimentation at scale**: multi-pipeline framework (traditional ML, Keras DL, HuggingFace transformers) with unified, security-first metrics and adaptive training
- **Deployment-grade API**: FastAPI service with a configurable policy gateway, structured logs, health checks, and optional downstream forwarding
- **Curation + EDA**: analyst-in-the-loop labeling UIs, curation APIs, and a notebook to produce balanced, sanitized replacement datasets and visuals
- **Artifacts and results**: organized results, model artifacts, and backup datasets

## Directory Details
### `5-Data_Wrangling/`
- Cleaning/assembly scripts and `data_processing_demo.ipynb`
- See `DEMO_README.md` for a step-by-step demo and statistics

### `7-Experiment_With_Models/`
- Production-grade experiment framework with configuration, training, evaluation, and visualization
- Run `python run_pipeline.py`
- Outputs: `results/` (CSV, images, reports), `models/` (artifacts)
- See `7-Experiment_With_Models/README.md` for full documentation

### `10_11_&_12-Deployment_Architecture/` (Steps 10–12)
- FastAPI service, UIs (`/ui`, `/reviewer`), curation APIs, EDA notebook, Docker, tests
- Key endpoints:
  - `GET /healthz` — health
  - `POST /classify_prompt` — classify only
  - `POST /gateway` — policy enforcement + optional forward
  - `GET|POST /config` — runtime policy/thresholds
  - Curation: `POST /ingest`, `GET /review/next`, `POST /review/{id}`, `GET /export/replace`
- Env configuration:
  - `HF_MODEL_ID` or `MODEL_PATH`, `BLOCK_LABELS`, `SUSPICIOUS_PASS_THRESHOLD`, `DOWNSTREAM_URL`, `INGEST_UI`
- See `10_11_&_12-Deployment_Architecture/README.md` for full details

### `9-Deployment_Method_&_Engineering_Plan/` (Step 9)
- Engineering plan: architecture, ops, CI/CD, SLOs, security, and runbooks

### `4-Survey_Existing_Research/`
- Survey and reproduced notebooks/code; contextualizes problem/approaches used

### `2-Data_Exploration/` and `3-Project_Proposal/`
- Early exploration artifacts and project proposal documents

## Visuals (generated by EDA notebook)
- `curation_overview.png`: label distribution, character lengths, word counts
- `trigrams_heatmap.png`: common trigrams across labels
- `word_count_distribution_analysis.png`: per-label distributions
- `words_heatmap_p1.png`–`p3.png`: top tokens excluding stopwords

Saved to `10_11_&_12-Deployment_Architecture/curation/visuals/`.

## Docker (optional)
- From `10_11_&_12-Deployment_Architecture/`: `docker-compose up --build`

## Rubric Mapping (Steps 9–12)
- **Step 9 — Deployment Method & Engineering Plan**
  - See `9-Deployment_Method_&_Engineering_Plan/Deployment_Method_and_Engineering_Plan.md`
- **Step 10 — Deployment Architecture**
  - See `10_11_&_12-Deployment_Architecture/README.md`
- **Step 11 — Deployment Implementation**
  - API, UIs, policy config, curation APIs, tests, load test
- **Step 12 — Share/Presentation**
  - Demo flow, visuals, and slides artifacts

## External Docs
- Slides/Supporting doc: [Google Doc](https://docs.google.com/document/d/1XR2jrcj17HJbwI5lyBWgFgL517oNfUaZQqr605-QXXA/edit?tab=t.0)
- Step 10 – Deployment Architecture: [Google Doc](https://docs.google.com/document/d/199UTvpOHjqiwnlPuibljDTAG5V9u6j6OfCBQuk_0fDw/edit?tab=t.0)
- Step 12 – Share/Presentation: [Google Doc](https://docs.google.com/document/d/199UTvpOHjqiwnlPuibljDTAG5V9u6j6OfCBQuk_0fDw/edit?tab=t.0)
